{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running training (fine tuning) and interface for ResNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure training flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from cnn.transfer.cnn_files import files as _files\n",
    "from cnn.transfer import dataset_config as datasets\n",
    "from cnn.transfer.data_visualizer import visualize_model\n",
    "from os.path import expanduser\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def join_home(dir_path):\n",
    "  \"\"\"Joins passed direcotry to home directory\n",
    "    Args:\n",
    "      dir_path - directory path\n",
    "    Returns:\n",
    "      path joined to home directory\n",
    "  \"\"\"\n",
    "  home_dir = expanduser('~')\n",
    "  full_dir = _files.join_path(home_dir, dir_path)\n",
    "  print(full_dir)\n",
    " \n",
    "  return full_dir\n",
    "\n",
    "def init_training_flags():\n",
    "    \n",
    "    tr_flags = type('TrainingFlags', (object,), {})\n",
    "    \n",
    "    tr_flags.fine_tune = True # Flag to choose between transfer and fine-tune model\n",
    "    # Configure training flags\n",
    "    tr_flags.fc_size =1024 # Fully connected layer size\n",
    "    \n",
    "    # Flags for convolutional layers\n",
    "    tr_flags.optimizer = 'adam'\n",
    "    tr_flags.batch_size = 32 # Training batch size\n",
    "    tr_flags.epochs = 5 # Number of training epochs\n",
    "    tr_flags.decay = 1e-6# Training decay\n",
    "    tr_flags.keep_prob = 0.2 # Dropout keep probability\n",
    "    tr_flags.keep_dense_prob = 0.5 # Dropout keep probability for fully connected layer\n",
    "    tr_flags.learning_rate = 0.0001 # Learning rate\n",
    "    tr_flags.weight_decay = 1e-4 # Weight decay\n",
    "    tr_flags.momentum = 0.9 # Learning momentum\n",
    "    tr_flags.val_precentage = 0.2 # Percentage of validation data\n",
    "    tr_flags.test_precentage = 0.2 # Percentage of test data\n",
    "    tr_flags.num_classes = 2 # Number of classes\n",
    "    tr_flags.trainable_layers = 15 # Number of layers to freeze\n",
    "\n",
    "    tr_flags.save_model = False # Prints data set file names and labels\n",
    "    tr_flags.image_width = 224 # Training image width\n",
    "    tr_flags.image_height = 224 # Training image height\n",
    "    tr_flags.image_channels = 3 # Training image height\n",
    "    tr_flags.verbose = True #'Log steps\n",
    "    tr_flags.plot = True #Flag to plot recognition\n",
    "    \n",
    "    # System configuration\n",
    "    tr_flags.num_workers=8\n",
    "\n",
    "    return tr_flags\n",
    "\n",
    "\n",
    "def get_cats_dogs_training_flags():\n",
    "\n",
    "    tr_flags = init_training_flags()\n",
    "    # Configure training flags\n",
    "    tr_flags.model_dir = join_home('models/cats_dogs/')\n",
    "    tr_flags.model = join_home('models/cats_dogs/resnet18.pth.tar') # Path to network model for prediction\n",
    "    tr_flags.weights = join_home('models/cats_dogs/resnet18.pth.tar') # Where to save the trained data\n",
    "\n",
    "    tr_flags.dataset_dir = join_home('datasets/cats_dogs/dataset_files/') #'Path to folders of labeled images for pre-processing and training.'\n",
    "    tr_flags.train_dir = join_home('datasets/cats_dogs/training') # Path to folders of labeled images for training.\n",
    "    tr_flags.val_dir = join_home('datasets/cats_dogs/validation') # Path to folders of labeled images for validation.\n",
    "    tr_flags.test_dir = join_home('datasets/cats_dogs/test') # Path to folders of labeled images for validation.\n",
    "\n",
    "    return tr_flags\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Levan/models/cats_dogs/\n",
      "/Users/Levan/models/cats_dogs/resnet18.pth.tar\n",
      "/Users/Levan/models/cats_dogs/resnet18.pth.tar\n",
      "/Users/Levan/datasets/cats_dogs/dataset_files/\n",
      "/Users/Levan/datasets/cats_dogs/training\n",
      "/Users/Levan/datasets/cats_dogs/validation\n",
      "/Users/Levan/datasets/cats_dogs/test\n",
      "Freeze for  2  layers\n",
      "Freeze for  3  layers\n",
      "Freeze for  3  layers\n",
      "Freeze for  3  layers\n",
      "Freeze for  4  layers\n",
      "Freeze for  5  layers\n",
      "Freeze for  5  layers\n",
      "Freeze for  6  layers\n",
      "Freeze for  7  layers\n",
      "Freeze for  8  layers\n",
      "Freeze for  9  layers\n",
      "Freeze for  9  layers\n",
      "Freeze for  10  layers\n",
      "Freeze for  11  layers\n",
      "Freeze for  12  layers\n",
      "Freeze for  13  layers\n",
      "Freeze for  13  layers\n",
      "Freeze for  14  layers\n",
      "Freeze for  15  layers\n",
      "Freeze for  16  layers\n",
      "Freeze for  17  layers\n",
      "Freeze for  18  layers\n",
      "Freeze for  19  layers\n",
      "Freeze for  19  layers\n",
      "Freeze for  20  layers\n",
      "Freeze for  21  layers\n",
      "Freeze for  22  layers\n",
      "Freeze for  23  layers\n",
      "Freeze for  23  layers\n",
      "Freeze for  24  layers\n",
      "Freeze for  25  layers\n",
      "Freeze for  26  layers\n",
      "Freeze for  27  layers\n",
      "Freeze for  28  layers\n",
      "Freeze for  29  layers\n",
      "Freeze for  29  layers\n",
      "Freeze for  30  layers\n",
      "Freeze for  31  layers\n",
      "Freeze for  32  layers\n",
      "Freeze for  33  layers\n",
      "Freeze for  33  layers\n",
      "Freeze for  34  layers\n",
      "Freeze for  35  layers\n",
      "Freeze for  36  layers\n",
      "Freeze for  37  layers\n",
      "Freeze for  38  layers\n",
      "Freeze for  39  layers\n",
      "Freeze for  39  layers\n",
      "Freeze for  40  layers\n",
      "Freeze for  41  layers\n",
      "Freeze for  41  layers\n",
      "Freeze for  42  layers\n",
      "Freeze for  42  layers\n",
      "Freeze for  43  layers\n",
      "Freeze for  44  layers\n",
      "Freeze for  45  layers\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-28:\n",
      "Process Process-25:\n",
      "Process Process-29:\n",
      "Process Process-27:\n",
      "Process Process-32:\n",
      "Process Process-26:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Process Process-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Process Process-31:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "    r = index_queue.get()\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    r = index_queue.get()\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    r = index_queue.get()\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    r = index_queue.get()\n",
      "  File \"/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "  File \"/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    buf = self.recv_bytes()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6de535e16b7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtr_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cats_dogs_training_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class_names - '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class_to_idx - '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Levan/git/conv-net-examples/cnn/transfer/finetune_model.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(flags)\u001b[0m\n\u001b[1;32m     63\u001b[0m   training_args = (renset_model, criterion, optimizer, scheduler,\n\u001b[1;32m     64\u001b[0m                    dataloders, dataset_sizes, flags)\n\u001b[0;32m---> 65\u001b[0;31m   \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m   \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;31m# visualize_model(renset_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Levan/git/conv-net-examples/cnn/transfer/train_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_args)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# Each epoch has a training and validation phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_PHASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAL_PHASE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m       \u001b[0mis_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAL_PHASE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0;31m# deep copy the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Levan/git/conv-net-examples/cnn/transfer/train_model.py\u001b[0m in \u001b[0;36mtrain_phase\u001b[0;34m(training_args, phase, use_gpu)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Levan/git/conv-net-examples/cnn/transfer/network_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Levan/git/conv-net-examples/cnn/resnet/resnet.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torchvision-0.1.9-py2.7.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 254\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     50\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     51\u001b[0m                _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cnn.transfer import finetune_model\n",
    "\n",
    "tr_flags = get_cats_dogs_training_flags()\n",
    "(class_names, class_to_idx) = finetune_model.run_training(tr_flags)\n",
    "print('class_names - ', class_names)\n",
    "print('class_to_idx - ', class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure interface flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_argparse = type('ArgumentParserImpl', (object,), {})\n",
    "in_argparse.print_help = lambda:print('No image or URL are given')\n",
    "\n",
    "def init_interface_flags():\n",
    "    \n",
    "    in_flags = type('InterfaceFlags', (object,), {})\n",
    "    # Configure interface flags\n",
    "    in_flags.fc_size =1024 # Fully connected layer size\n",
    "    in_flags.num_classes = 2 # Number of classes\n",
    "    in_flags.save_model = False #Prints data set file names and labels\n",
    "    in_flags.image_width = 224 # Training image width\n",
    "    in_flags.image_height = 224 # Training image height\n",
    "    in_flags.image_channels = 3 # Training image height\n",
    "    in_flags.verbose = True #'Log steps\n",
    "    in_flags.labels = None\n",
    "    in_flags.plot = True #Flag to plot recognition\n",
    "    \n",
    "    # Network architecture\n",
    "    in_flags.keep_prob = 0.2 # Dropout keep probability\n",
    "    in_flags.keep_dense_prob = 0.5 # Dropout keep probability for fully connected layer\n",
    "\n",
    "    return in_flags\n",
    "\n",
    "\n",
    "def get_cats_dogs_interface_flags():\n",
    "\n",
    "    in_flags = init_interface_flags()\n",
    "    # Configure interface flags\n",
    "    in_flags.image = join_home('datasets/cats_dogs/test1/10336.jpg') # Path to image for prediction\n",
    "    in_flags.url = None # URL to image for prediction\n",
    "    in_flags.model=join_home('models/cats_dogs/resnet18.pth.tar') # Path to network model for prediction\n",
    "    in_flags.weights = join_home('models/cats_dogs/resnet50.h5') # Where to save the trained data\n",
    "    in_flags.train_dir = join_home('datasets/cats_dogs/resnet18.pth.tar') # Path to folders of labeled images for training.\n",
    "\n",
    "    return in_flags\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs prediction on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pulsarai/datasets/revenue/dataset/test1/10336.jpg\n",
      "/home/pulsarai/models/revenue/resnet18.pth.tar\n",
      "/home/pulsarai/models/revenue/resnet18.pth.tar\n",
      "/home/pulsarai/datasets/revenue/dataset/training_files/training\n",
      "['apples', 'background', 'bags', 'bottles', 'firearms', 'glasses', 'knives', 'water_glasses', 'wine_glasses', 'wristwatch']\n",
      "{'bags': 2, 'bottles': 3, 'water_glasses': 7, 'firearms': 4, 'wristwatch': 9, 'wine_glasses': 8, 'knives': 6, 'apples': 0, 'background': 1, 'glasses': 5}\n",
      "/home/pulsarai/datasets/revenue/dataset/test1\n",
      "Variable containing:\n",
      "-0.4159 -0.9739  0.5404  0.5119 -0.0790 -0.8078  0.3341  0.6180  0.2277  0.6612\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n",
      "[9]\n",
      "predicted: wristwatch\n",
      "/home/pulsarai/datasets/revenue/dataset/test1\n",
      "Variable containing:\n",
      "-0.3564  0.2263  0.4608  0.4497 -0.3473 -0.3092 -0.2661  0.3706  0.3678  0.1494\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n",
      "[2]\n",
      "predicted: bags\n",
      "/home/pulsarai/datasets/revenue/dataset/test1\n",
      "Variable containing:\n",
      "-0.6384 -0.4509 -0.3255  0.2486 -0.2523  0.2014 -0.4065  0.4247  1.6346  0.3829\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n",
      "[8]\n",
      "predicted: wine_glasses\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from cnn.transfer import (network_model as networks,\n",
    "                          network_interface as interface)\n",
    "from cnn.resnet.resnet import resnet18\n",
    "from utils.config import dataset_reader as reader\n",
    "\n",
    "text = widgets.Text()\n",
    "button = widgets.Button(description='Submit')\n",
    "display(text)\n",
    "display(button)\n",
    "\n",
    "image_suffix = ''\n",
    "\n",
    "in_flags = get_revenue_interface_flags()\n",
    "model = networks.init_model_and_weights(in_flags, resnet18)\n",
    "model.eval()\n",
    "(class_names, index_labels) = datasets.read_labels(in_flags.train_dir)\n",
    "print(class_names)\n",
    "print(index_labels)\n",
    "\n",
    "def retrieve_labels(flags):\n",
    "  \"\"\"Retrieve label names\n",
    "    Args:\n",
    "      flags - training flags\n",
    "    Returns:\n",
    "      training labels\n",
    "  \"\"\"\n",
    "  return datasets.read_labels(flags.train_dir)\n",
    "\n",
    "\n",
    "from cnn.transfer.dataset_config import validation_trandorms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def handle_text(sender_value):\n",
    "    image_suffix = text.value\n",
    "    image_prefix = join_home('datasets/revenue/dataset/test1')\n",
    "    image_path = _files.join_path(image_prefix, image_suffix)\n",
    "    \n",
    "    \n",
    "    predictions = interface.run_on_path(model, image_path)\n",
    "    print(predictions)\n",
    "    (_, preds) = torch.max(predictions.data, 1)\n",
    "    data_idx = Variable(preds).data.numpy()\n",
    "    print(data_idx)\n",
    "    print('predicted: {}'.format(class_names[data_idx[0]]))\n",
    "    \n",
    "button.on_click(handle_text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {
    "3b860209fd524db79874d730ef475323": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "769b91cccae94fce80655dfdac528be9": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "865355fe8fa7423f8f71bf84792d1057": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "9fab060726564a0abe4273ed1df30182": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "affe91b7a70c4ae29c383a2cc1cd15c6": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
