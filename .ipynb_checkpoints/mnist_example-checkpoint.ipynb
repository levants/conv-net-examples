{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure training flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from cnn.mnist.cnn_files import files as _files\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def init_training_flags():\n",
    "    \n",
    "    tr_flags = type('TrainingFlags', (object,), {})\n",
    "    \n",
    "    tr_flags.batch_size = 64\n",
    "    tr_flags.test_batch_size = 1000\n",
    "    tr_flags.epochs = 10\n",
    "    tr_flags.no_cuda = False\n",
    "    tr_flags.seed = 1\n",
    "    tr_flags.log_interval = 10\n",
    "    tr_flags.weights = _files.model_file('mnist_weights.pth.tar')\n",
    "    tr_flags.lr = 0.01\n",
    "    tr_flags.momentum = 0.5\n",
    "    \n",
    "    # System configuration\n",
    "    tr_flags.num_workers=8\n",
    "    \n",
    "    tr_flags.cuda = False\n",
    "\n",
    "    return tr_flags\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import (datasets, transforms)\n",
    "\n",
    "flags = init_training_flags()\n",
    "\n",
    "torch.manual_seed(flags.seed)\n",
    "if flags.cuda:\n",
    "  torch.cuda.manual_seed(flags.seed)\n",
    "\n",
    "kwargs = {'num_workers': flags.num_workers, 'pin_memory': True} if flags.cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  datasets.MNIST(_files.data_dir, train=True, download=True,\n",
    "                 transform=transforms.Compose([\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.1307,), (0.3081,))\n",
    "                 ])),\n",
    "  batch_size=flags.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  datasets.MNIST(_files.data_dir, train=False, transform=transforms.Compose([\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.1307,), (0.3081,))\n",
    "                 ])),\n",
    "  batch_size=flags.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.models.layers import Flatten\n",
    "\n",
    "\n",
    "class LeNetClassic(nn.Module):\n",
    "  \"\"\"Network model without flatten layer\n",
    "   for character recognition\"\"\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(LeNetClassic, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "    self.conv2_drop = nn.Dropout2d()\n",
    "    self.fc1 = nn.Linear(320, 50)\n",
    "    self.fc2 = nn.Linear(50, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      \n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "    x = x.view(x.size(0), 320)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "    result = F.log_softmax(x)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "  \"\"\"Network model with flatten layer\n",
    "   for character recognition\"\"\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(LeNet, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "    self.conv2_drop = nn.Dropout2d()\n",
    "    self.flatten = Flatten(50)\n",
    "    self.fc2 = nn.Linear(50, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      \n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "    x = self.flatten(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "    result = F.log_softmax(x)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "class LeNetSequential(nn.Module):\n",
    "  \"\"\"Network model with flatten layer\n",
    "   for character recognition\"\"\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(LeNetSequential, self).__init__()\n",
    "    self.conv_part = nn.Sequential(nn.Conv2d(1, 10, kernel_size=5),\n",
    "                                   nn.MaxPool2d(2, 2),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(10, 20, kernel_size=5),\n",
    "                                   nn.MaxPool2d(2, 2),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout2d())\n",
    "    self.flatten = Flatten(50)\n",
    "    self.fc2 = nn.Linear(50, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      \n",
    "    x = self.conv_part(x)\n",
    "    x = self.flatten(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "    result = F.log_softmax(x)\n",
    "    \n",
    "    return result\n",
    "  \n",
    "  \n",
    "class LeNetSequentialDict(nn.Module):\n",
    "  \"\"\"Network model with flatten layer\n",
    "   for character recognition\"\"\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(LeNetSequentialDict, self).__init__()\n",
    "    self.conv_part = nn.Sequential(OrderedDict([\n",
    "                                   ('conv1', nn.Conv2d(1, 10, kernel_size=5)),\n",
    "                                   ('mxpl1', nn.MaxPool2d(2, 2)),\n",
    "                                   ('relu1', nn.ReLU()),\n",
    "                                   ('conv2', nn.Conv2d(10, 20, kernel_size=5)),\n",
    "                                   ('mxol2', nn.MaxPool2d(2, 2)),\n",
    "                                   ('relu2', nn.ReLU()),\n",
    "                                   ('drop1', nn.Dropout2d())]))\n",
    "    self.flatten = Flatten(50)\n",
    "    self.fc2 = nn.Linear(50, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      \n",
    "    x = self.conv_part(x)\n",
    "    x = self.flatten(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "    result = F.log_softmax(x)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End=attachment\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.291420\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.320766\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.293607\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.262021\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.299063\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.253126\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.246339\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.265384\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.266011\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.283992\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.210891\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.295862\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.198273\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.182696\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.153505\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.201344\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.230200\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.240868\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.217868\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.112736\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.156068\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.178810\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.129399\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.031767\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.068239\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.034646\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.977391\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.028165\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.164184\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.079583\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.892469\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.964220\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.853038\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 1.907249\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.994120\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.759810\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.843805\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.688725\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.687753\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 1.791064\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.745659\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.737184\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.616161\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.721229\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.677802\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.692048\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.532345\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 1.724192\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.611442\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.711347\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.636567\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.676730\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.541104\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.558402\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.295197\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.563232\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.708238\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.472936\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.821081\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.783729\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.488430\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.555138\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.522293\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.331037\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.421486\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.483827\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.354248\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 1.242108\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.420267\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 1.313802\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.292753\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 1.387907\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.622858\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 1.295196\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.401664\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.433012\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.268681\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 1.404006\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.388049\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 1.264344\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.499619\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.331190\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.202865\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.422148\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.229261\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.201460\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.404083\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.324110\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.364823\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.062346\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.239828\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.284710\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.392458\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.190152\n",
      "\n",
      "Test set: Average loss: 0.7624, Accuracy: 8516/10000 (85%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.228152\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.457571\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.052948\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.244678\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.271386\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.414198\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.321833\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 1.232918\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.397323\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 1.326272\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.342396\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 1.211623\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.268281\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 1.234864\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.146027\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.503926\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.388075\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 1.165922\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 1.081704\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 1.309844\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.251435\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.214265\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 1.208019\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.110336\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.297383\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.077795\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.250504\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.050215\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.134043\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.980355\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.276561\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 1.249015\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.347679\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.078518\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.150693\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1.256007\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.901270\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 1.289710\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.125713\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.088946\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.513241\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.243192\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.260201\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 1.095798\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.134872\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.240025\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.288603\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.181124\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.270334\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.107325\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.237882\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.213130\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.094857\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.427439\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.926785\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.893043\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.414040\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.144353\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.160817\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 1.171524\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.207838\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.102511\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.379873\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 1.191146\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.085245\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.185285\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.106856\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 1.086750\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.922406\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.230150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.823559\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.031581\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.069610\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.992646\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.070144\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.196937\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.013552\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.007919\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.403352\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.017321\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.067889\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 1.226116\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.975467\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 1.086594\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.060130\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.025473\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.512197\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.115833\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.938655\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.328765\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.169865\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.476341\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.990278\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.336521\n",
      "\n",
      "Test set: Average loss: 0.5352, Accuracy: 8975/10000 (90%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.937887\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 1.474595\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.213292\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 1.056998\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.738082\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1.079202\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.148675\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 1.153385\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.074069\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 1.204178\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.064520\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.788312\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.050491\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 1.114527\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.098098\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1.150846\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.186357\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 1.048602\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.286368\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.923330\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.229379\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 1.072901\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 1.277830\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 1.038206\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.963763\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.088141\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.256730\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 1.213028\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.052356\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 1.035732\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.138711\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 1.206847\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.924367\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 1.038170\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.004218\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1.102595\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.018299\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.997533\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.027122\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.744913\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.928336\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.858095\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.908431\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.982466\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.863474\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1.085161\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.126095\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 1.028457\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.951891\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.850472\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.159574\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.942810\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 1.084534\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 1.012863\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.871786\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1.013155\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.147406\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.858473\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.024484\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 1.138949\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.809558\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.894751\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.059653\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.939983\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.384978\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.980779\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 1.289330\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 1.007890\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.788583\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.618826\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.895192\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.972617\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.997256\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 1.116844\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.081937\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.021062\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.011088\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.975645\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.169867\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 1.201456\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.046230\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.842138\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 1.026661\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.936557\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.890446\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.831523\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.985862\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 1.115277\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.872746\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.968774\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.905873\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.864594\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.062457\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.957463\n",
      "\n",
      "Test set: Average loss: 0.4429, Accuracy: 9154/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.758235\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 1.125624\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 1.128398\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.691076\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.733733\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.952654\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.762428\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 1.136057\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.831966\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.999673\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.719267\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.812055\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 1.159646\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.777406\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 1.170701\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.993327\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.976663\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.973696\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 1.207790\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.687131\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.674638\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 1.024376\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.771087\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.803299\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.884438\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.982133\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 1.080507\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.725370\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 1.005224\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 1.114930\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.973496\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 1.177368\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 1.164846\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 1.117746\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 1.186737\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.994465\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 1.024677\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.875770\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.807537\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.843516\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.864291\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 1.135666\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.967912\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 1.158867\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 1.027524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.580717\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.886387\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 1.135479\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.959838\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.959866\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.949440\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.977598\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.698675\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 1.198358\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.887278\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.838312\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 1.095731\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 1.114238\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.752053\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.736348\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.205590\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 1.154064\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 1.028600\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 1.042127\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.988634\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 1.061889\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 1.085494\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 1.167712\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.718037\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.818131\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.807154\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.958345\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.621388\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.859744\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.840857\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.862173\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.831620\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 1.072171\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.778809\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.778480\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.776576\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 1.116176\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.960233\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 1.173506\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.773894\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.731817\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.929835\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.784971\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.719457\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.993884\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.983680\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 1.562116\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.917424\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.960319\n",
      "\n",
      "Test set: Average loss: 0.3700, Accuracy: 9261/10000 (93%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.869991\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.730058\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 1.122316\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.798992\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.956241\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.881094\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.966682\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.902646\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.881225\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.799608\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.711389\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.836372\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.736728\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.932714\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.866022\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.864294\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 1.091926\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.929180\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.919913\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.726023\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.844291\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.749246\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.762792\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.832141\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.912381\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.075280\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.824115\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.803712\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.999020\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.975501\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.833104\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.862598\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.829520\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.861917\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.891807\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 1.012872\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.807639\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.645101\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.892945\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.946555\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.865527\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.823926\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.857859\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 1.003160\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.618790\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 1.043769\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.788178\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 1.048978\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.744371\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.919695\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.867403\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.858453\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.971110\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.841384\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.972755\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 1.127476\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.945194\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.935871\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.802679\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.904022\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.014693\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.932999\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.765636\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.831922\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.698549\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.962232\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.838804\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.852863\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.823628\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.651785\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.744995\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.726501\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 1.081310\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.700610\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 1.113734\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.726544\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.753398\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.751963\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.636114\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.806890\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.638920\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.972752\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.696767\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.934400\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.714713\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.930761\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.860313\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.814180\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.810724\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.751435\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.259068\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.756660\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.750299\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.802849\n",
      "\n",
      "Test set: Average loss: 0.3227, Accuracy: 9302/10000 (93%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.893907\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.601279\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.826812\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.627983\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 1.017546\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 1.003109\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.867933\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 1.023778\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.811924\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.988755\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.914509\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.996427\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.876305\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.660782\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.862837\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.960003\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.783384\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.706784\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 1.186716\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.781174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.797495\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.788341\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.698124\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.821524\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.977970\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.684955\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 1.049334\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.724926\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.956910\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.863667\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.766245\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.853020\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.584582\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.871847\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.747976\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.954876\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.787820\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.913367\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.950986\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 1.040218\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.937295\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.872743\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.650034\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.839398\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.901635\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.963332\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.761169\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.769785\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.793469\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.895450\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.933846\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.853965\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.717581\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.707447\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.778079\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.740787\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.682079\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.972924\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 1.039328\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.836301\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.961996\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.687699\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.850695\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.828680\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.773128\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 1.037756\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 1.160894\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.672489\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.602905\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.962668\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.872087\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 1.044830\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.791422\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 1.068224\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.811894\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 1.153437\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.837555\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.841952\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.664547\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.906915\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.212359\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.994719\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.512201\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.711919\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.778406\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.899533\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.927871\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.736184\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.956568\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.636324\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.889887\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.937028\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.776722\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.717566\n",
      "\n",
      "Test set: Average loss: 0.2875, Accuracy: 9383/10000 (94%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.739954\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.674860\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.927679\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.656263\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.853417\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.881692\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.853188\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.592500\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.622933\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.718545\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.444126\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.503105\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.789693\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 1.033102\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.880360\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.608402\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.806874\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.896963\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.764357\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.795498\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.189173\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.660600\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.841919\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.768869\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.761945\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.903501\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.835848\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.661751\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.849226\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.961356\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.859645\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 1.000231\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.641805\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.832133\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.681475\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.654451\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.750212\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.589205\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.639926\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.935981\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.963658\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.758393\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.507777\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.778517\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.908096\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.670880\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.678767\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.644247\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.717760\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.846861\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.713908\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.857447\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.635848\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.896702\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.969916\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 1.105067\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.747265\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.863667\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.818501\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.679867\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.871174\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.847604\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.870017\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.879531\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.850372\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.683484\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.718069\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.656650\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.677466\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.620408\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.694486\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.688104\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.743959\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.769147\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.842766\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.637749\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.854869\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.879806\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.886724\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.836614\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.783813\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.794335\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.795543\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.815820\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 1.075003\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.708894\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.879376\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.712762\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.986832\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.710252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.557062\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.694381\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.744915\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.905197\n",
      "\n",
      "Test set: Average loss: 0.2659, Accuracy: 9486/10000 (95%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.750619\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.650739\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.915138\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.974229\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.713361\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.868833\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.971016\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.944800\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.804861\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.821842\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.728135\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.764291\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.881551\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.890386\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.736806\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.851218\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.847581\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.770176\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.877168\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.834683\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.006078\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.793721\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.753646\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.659136\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.890341\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.682281\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.788505\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.788532\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.688004\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.616917\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.721027\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.850416\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.730545\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.951742\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.631787\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.856273\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.551318\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.860628\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.566447\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.661405\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.681335\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.932772\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.876866\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.735922\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.922130\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.563839\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.939707\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.834354\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.788178\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.617908\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.836734\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.720863\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.534431\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.492223\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 1.032664\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.742696\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 1.157818\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.895673\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.682087\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.604252\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.837806\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.681599\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.484837\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.497964\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 1.019885\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.915983\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.729697\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.816797\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.959240\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.766447\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.919597\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.540207\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.754708\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.756474\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.556063\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.681618\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.727600\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.768472\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.787299\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.706414\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.795131\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.526869\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.711891\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.665393\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 1.083378\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.677494\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.705938\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.653131\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.679783\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.487216\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.718313\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.851799\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.653193\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.595105\n",
      "\n",
      "Test set: Average loss: 0.2344, Accuracy: 9529/10000 (95%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.473896\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.865500\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.790780\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.650153\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.827872\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.706720\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.837786\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.945853\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.579684\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.661096\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.790461\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.951072\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.601693\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.721831\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.497635\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.736094\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.620260\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.845157\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.747649\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.806824\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.659188\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.805014\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.786532\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.790658\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 1.061844\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.033452\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.658387\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.542885\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.788658\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.665283\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.576556\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.735942\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.755664\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.607953\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.558597\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 1.138611\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.969654\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.933941\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.496757\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.895208\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.097015\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.607112\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.528836\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.492622\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.909961\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.788532\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.534151\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.550572\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.693728\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.701075\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.811683\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.745981\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.585297\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.838639\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.981418\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.834980\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.839956\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.897395\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.590128\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.753690\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.719043\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.714637\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.628732\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.665082\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.661918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.757240\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.826704\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.780100\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.795745\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.509552\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.683279\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.822753\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.681254\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.691773\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.993729\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.659368\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 1.005893\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.821565\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.856251\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.477131\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.472896\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.712545\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 1.002561\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.750750\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.809389\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.657938\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.699670\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.593376\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.822646\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.783403\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.668066\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.702246\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.487767\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.677477\n",
      "\n",
      "Test set: Average loss: 0.2191, Accuracy: 9546/10000 (95%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.614748\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.629350\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.654744\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.526889\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.582503\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.716925\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.617907\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.802104\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.546115\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.734825\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.730590\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.670385\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.778885\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.572219\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.620513\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.542415\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.723162\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.723961\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.675384\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.621636\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.514687\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.828806\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.712553\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 1.210947\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.482151\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.668669\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.644874\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.704331\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.667465\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.773877\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.513628\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.634488\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.912174\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.722357\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.520713\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.506127\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.749967\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.733659\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.758070\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.590388\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.666729\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.733013\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.553390\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.507808\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.591551\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.635556\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.600088\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.740913\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.558585\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.581878\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.886354\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.678681\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.780109\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.772344\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.585250\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.724603\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.721600\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.918729\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.507644\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.682745\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.823838\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.891643\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.581079\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.649894\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.886809\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.600489\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.610904\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.666291\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.926956\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.779090\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.874654\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.717940\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.659459\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.675652\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.531371\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.631821\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.641232\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.761971\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.589335\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.683077\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.762762\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.628271\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.792094\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.860847\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.786537\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.812609\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.598077\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.778647\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.687827\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.622211\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.563585\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.951968\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.704637\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.733536\n",
      "\n",
      "Test set: Average loss: 0.2152, Accuracy: 9553/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(epoch, training_config):\n",
    "  \"\"\"Train network model\n",
    "    Args:\n",
    "      epoch - current epoch\n",
    "      training_config - training configuration tuple\n",
    "  \"\"\"\n",
    "    \n",
    "  (train_loader, model, optimizer, flags) = training_config\n",
    "  model.train()\n",
    "  for (batch_idx, (data, target)) in enumerate(train_loader):\n",
    "    if flags.cuda:\n",
    "        (data, target) = (data.cuda(), target.cusa())\n",
    "    (data, target) = (Variable(data), Variable(target))\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % flags.log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "          100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "  torch.save(model.state_dict(), flags.weights)\n",
    "  \n",
    "\n",
    "def test(test_loader, model, flags):\n",
    "  \"\"\"Test network\n",
    "    test_loader - test data loader\n",
    "    model - network model\n",
    "    flags - configuration parameters\n",
    "  \"\"\"\n",
    "    \n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  for (data, target) in test_loader:\n",
    "    if flags.cuda:\n",
    "        (data, target) = (data.cuda(), target.cusa())\n",
    "    (data, target) = (Variable(data, volatile=True), Variable(target))\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target, size_average=False).data[0]  # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "model = LetterNet()\n",
    "\n",
    "if flags.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "print('End=attachment')\n",
    "optimizer = optim.SGD(model.parameters(), lr=flags.lr, momentum=flags.momentum)\n",
    "training_config = (train_loader, model, optimizer, flags)\n",
    "for epoch in range(1, flags.epochs + 1):\n",
    "    train(epoch, training_config)\n",
    "    test(test_loader, model, flags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {
    "3b860209fd524db79874d730ef475323": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "769b91cccae94fce80655dfdac528be9": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "865355fe8fa7423f8f71bf84792d1057": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "9fab060726564a0abe4273ed1df30182": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "affe91b7a70c4ae29c383a2cc1cd15c6": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
